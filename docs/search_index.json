[
["independance.html", "Chapitre 2 Test ind√©pendance 2.1 Test de corr√©lation 2.2 Test du CHI¬≤ 2.3 ANOVA 1 2.4 ANOVA 2", " Chapitre 2 Test ind√©pendance Les tests d‚Äôind√©pendances permettent de d√©finir s‚Äôil existe un lien entre deux variables. Il existe diff√©rent test d‚Äôind√©pence, en voici quelques exemples : Test ind√©pendance entre deux variables quantitatives / Test de corr√©lation Pearson Test d‚Äôind√©pendance entre deux variables qualitatives / Test du Chi¬≤ Test d‚Äôind√©pendance entre une variable qualitative et une quantitative / Test de Fisher avec l‚Äôanalyse de la variance (ANOVA) 2.1 Test de corr√©lation L‚Äôint√©r√™t des tests de corr√©lation est d‚Äôapporter plus de pertinence et fiabilit√© aux coefficients de corr√©lation. Il existe diff√©rents test de corr√©lation, nous utilisons celui de Pearson. On travaille avec le jeu de donn√©es fromage üßÄ df &lt;- read.csv(file = &quot;./datasets/fromage.txt&quot;, sep = &quot;\\t&quot;, row.names = 1) calories sodium calcium lipides retinol folates proteines cholesterol magnesium CarredelEst 314 353.5 72.6 26.3 51.6 30.3 21.0 70 20 Babybel 314 238.0 209.8 25.1 63.7 6.4 22.6 70 27 Beaufort 401 112.0 259.4 33.3 54.9 1.2 26.6 120 41 Bleu 342 336.0 211.1 28.9 37.1 27.5 20.2 90 27 Camembert 264 314.0 215.9 19.5 103.0 36.4 23.4 60 20 Cantal 367 256.0 264.0 28.8 48.8 5.7 23.0 90 30 plot(df) library(corrplot) corrplot(cor(df, method = &quot;pearson&quot;)) On pose les hypoth√®ses de d√©part : H0 : Variables ind√©pendantes si p-value &gt; 5% H1 : Variables non ind√©pendantes si p-value &lt; 5% 2.1.1 Lipide vs Magnesium La premi√®re sortie correspond au coefficient de corr√©lation, la seconde √† la p-value (ou probabilit√© critique) cor(x = df$lipides, y = df$magnesium) ## [1] 0.6898601 cor.test(x = df$lipides, y = df$magnesium) ## ## Pearson&#39;s product-moment correlation ## ## data: df$lipides and df$magnesium ## t = 4.9515, df = 27, p-value = 3.469e-05 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4327766 0.8431785 ## sample estimates: ## cor ## 0.6898601 H1 : Variables non ind√©pendantes 2.1.2 Sodium vs Retinol cor.test(x = df$sodium, y = df$retinol) ## ## Pearson&#39;s product-moment correlation ## ## data: df$sodium and df$retinol ## t = 0.75788, df = 27, p-value = 0.4551 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.2345870 0.4851693 ## sample estimates: ## cor ## 0.1443276 H0 : Variables ind√©pendantes si p-value &gt; 5% Si on veut rejeter H0 et prendre H1, j‚Äôai 45,5% de chance de me tromper Les tests statistiques sont tr√©s sensibles √† la taille de l‚Äô√©chantillon. Un coefficient de corr√©lation de 0.14 n‚Äôaura pas la m√™me significativit√© sur un √©chantillon de 29 fromages qu‚Äôun √©chantillon de 319 fromages avec le m√™me coefficient de corr√©lation. On construit un dataframe en dupliquant le nombre de lignes sodium &lt;- rep(df$sodium,times = 10) retinol &lt;- rep(df$retinol,times = 10) nom &lt;- rep(rownames(df),times = 10) df_10 &lt;- data.frame(nom,sodium,retinol) Chaque fromage appara√Æt plusieurs fois, on a augment√© la taille de l‚Äô√©chantillon table(df_10$nom) ## ## Babybel Beaufort Bleu ## 10 10 10 ## Camembert Cantal CarredelEst ## 10 10 10 ## Chabichou Chaource Cheddar ## 10 10 10 ## Comte Coulomniers Edam ## 10 10 10 ## Emmental Fr.chevrepatemolle Fr.fondu.45 ## 10 10 10 ## Fr.frais20nat. Fr.frais40nat. Maroilles ## 10 10 10 ## Morbier Parmesan Petitsuisse40 ## 10 10 10 ## PontlEveque Pyrenees Reblochon ## 10 10 10 ## Rocquefort SaintPaulin Tome ## 10 10 10 ## Vacherin Yaourtlaitent.nat. ## 10 10 On effectue un autre test de corr√©lation avec les m√™mes variables sur l‚Äô√©chantillon plus grand. cor.test(x = df_10$sodium, y = df_10$retinol) ## ## Pearson&#39;s product-moment correlation ## ## data: df_10$sodium and df_10$retinol ## t = 2.4752, df = 288, p-value = 0.01389 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.0296407 0.2552637 ## sample estimates: ## cor ## 0.1443276 H1 : Variables non ind√©pendantes On obtient logiquement le m√™me coefficient de corr√©lation, mais en revanche, cette fois si la p-value est proche de 0. 2.1.3 Matrice des p-values On effectue un test de corr√©lation sur chaque variable 2 √† 2 en isolant uniquement la p-value get_pvalue &lt;- function(x,y){ p &lt;- cor.test(df[,x],df[,y])$p.value return(p) } colonne &lt;- colnames(df) ligne &lt;- colnames(df) df_pvalues &lt;- outer(X = colonne, Y = ligne, FUN = Vectorize(get_pvalue)) colnames(df_pvalues) &lt;- colnames(df) rownames(df_pvalues) &lt;- colnames(df) On affiche la matrice des corr√©lations avec un gradiant de couleur corrplot(df_pvalues, cl.lim=c(0,1), method=&quot;number&quot;, type=&quot;upper&quot;, col=colorRampPalette(c(&quot;white&quot;,&quot;white&quot;,&quot;red&quot;,&quot;yellow&quot;,&quot;green&quot;))(20)) 2.1.4 Cas de relation non lin√©aire Les diff√©rents de corr√©lation sont beaucoup plus adapt√©s aux relation lin√©aire. C‚Äôest pourquoi il est important de toujours visualiser les distributions (plus d‚Äôinfos ici). Cas d‚Äôune relation non-lin√©aire et non-monotone x &lt;- -10:10 y &lt;- x^2 + rnorm(n = length(x)) plot(x,y) cor.test(x, y, method = &quot;pearson&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: x and y ## t = 0.028197, df = 19, p-value = 0.9778 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.4264087 0.4369354 ## sample estimates: ## cor ## 0.006468781 cor.test(x, y, method = &quot;spearman&quot;) ## ## Spearman&#39;s rank correlation rho ## ## data: x and y ## S = 1518, p-value = 0.9528 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.01428571 cor.test(x, y, method = &quot;kendall&quot;) ## ## Kendall&#39;s rank correlation tau ## ## data: x and y ## T = 105, p-value = 1 ## alternative hypothesis: true tau is not equal to 0 ## sample estimates: ## tau ## 0 2.2 Test du CHI¬≤ L‚Äôint√©r√™t du test du Chi¬≤ est de mesurer l‚Äôind√©pendance entre deux variables qualitatives √† partir de tableau de contigence. 2.2.1 Titanic On travaille sur le jeu de donn√©es Titanic üßä‚õ¥ df &lt;- read.csv(file = &quot;./datasets/Titanic.csv&quot;, row.names = 1) Name PClass Age Sex Survived SexCode Allen, Miss Elisabeth Walton 1st 29.00 female 1 1 Allison, Miss Helen Loraine 1st 2.00 female 0 1 Allison, Mr Hudson Joshua Creighton 1st 30.00 male 0 0 Allison, Mrs Hudson JC (Bessie Waldo Daniels) 1st 25.00 female 0 1 Allison, Master Hudson Trevor 1st 0.92 male 1 0 Anderson, Mr Harry 1st 47.00 male 1 0 df_count &lt;- table(df$Survived, df$PClass) On pose : H0 : Variables ind√©pendantes si p-value &gt; 5% H1 : Variables non ind√©pendantes si p-value &lt; 5% resultat &lt;-chisq.test(df$Survived,df$PClass) resultat ## ## Pearson&#39;s Chi-squared test ## ## data: df$Survived and df$PClass ## X-squared = 172.3, df = 2, p-value &lt; 2.2e-16 H1 : Variables non ind√©pendantes La fonction attributes permet d‚Äôafficher les diff√©rentes sorties calcul√©es. attributes(resultat) ## $names ## [1] &quot;statistic&quot; &quot;parameter&quot; &quot;p.value&quot; &quot;method&quot; &quot;data.name&quot; &quot;observed&quot; ## [7] &quot;expected&quot; &quot;residuals&quot; &quot;stdres&quot; ## ## $class ## [1] &quot;htest&quot; Par exemple le tableau des effectifs th√©oriques. resultat$expected ## df$PClass ## df$Survived 1st 2nd 3rd ## 0 211.642 184.03656 467.3214 ## 1 110.358 95.96344 243.6786 2.2.2 Exemple du support data &lt;- matrix(rbind(c(693,886,534,153),c(597,696,448,95)),ncol=4) data ## [,1] [,2] [,3] [,4] ## [1,] 693 886 534 153 ## [2,] 597 696 448 95 chisq.test(data) ## ## Pearson&#39;s Chi-squared test ## ## data: data ## X-squared = 6.0504, df = 3, p-value = 0.1092 H0 : Variables ind√©pendantes Si on veut rejeter H0 et prendre H1, j‚Äôai 10,9% de chance de me tromper Lecture dans la table du Chi2 p &lt;- seq(0.80, 0.90, 0.005) dof &lt;- seq(1,3) chisq_table &lt;- outer(p, dof, function(x,y) qchisq(x,y)) chisq_table &lt;- t(chisq_table) colnames(chisq_table) &lt;- 1 - p rownames(chisq_table) &lt;- dof chisq_table &lt;- round(chisq_table,2) 0.2 0.195 0.19 0.185 0.18 0.175 0.17 0.165 0.16 0.155 0.15 0.145 0.14 0.135 0.13 0.125 0.12 0.115 0.11 0.105 0.1 1 1.64 1.68 1.72 1.76 1.80 1.84 1.88 1.93 1.97 2.02 2.07 2.12 2.18 2.23 2.29 2.35 2.42 2.48 2.55 2.63 2.71 2 3.22 3.27 3.32 3.37 3.43 3.49 3.54 3.60 3.67 3.73 3.79 3.86 3.93 4.00 4.08 4.16 4.24 4.33 4.41 4.51 4.61 3 4.64 4.70 4.76 4.83 4.89 4.96 5.02 5.09 5.17 5.24 5.32 5.40 5.48 5.56 5.65 5.74 5.83 5.93 6.03 6.14 6.25 üì¢ Taille de l‚Äô√©chantillon Les tests d‚Äôind√©pendance sont tr√©s sensibles √† la taille des √©chantillons. Ici on divise par 100 pour avoir des effectifs faibles mais en conservant les r√©partitions. chisq.test(data/100) ## ## Pearson&#39;s Chi-squared test ## ## data: data/100 ## X-squared = 0.060504, df = 3, p-value = 0.9961 H0 : Variables ind√©pendantes Ici on multiplie par 100 pour avoir des effectifs grands mais en conservant les r√©partitions chisq.test(data*100) ## ## Pearson&#39;s Chi-squared test ## ## data: data * 100 ## X-squared = 605.04, df = 3, p-value &lt; 2.2e-16 H1 : Variables non ind√©pendantes 2.3 ANOVA 1 On effectue une analyse de variance pour mesurer l‚Äôind√©pendance entre une variable qualitative et une quantitative. Pour illustrer cela, on utilise le jeu de donn√©es Hotdogs üå≠. df &lt;- read.csv(file = &quot;./datasets/Hotdogs.csv&quot;, sep = &quot;;&quot;) Type Calories Sodium Beef 186 495 Beef 181 477 Beef 176 425 Beef 149 322 Beef 184 482 Beef 190 587 On va tester l‚Äôind√©pendance entre la variable qualitative Type et la variable quantitatives Calories. boxplot(Calories ~ Type, data = df, horizontal = TRUE) Dans une ANOVA, on cherche √† d√©terminer si les moyennes des groupes sont significativement diff√©rentes. On pose donc : H0 : Les moyennes de chaque groupe sont √©gales si p-value &gt; 5% H1 : Les moyennes de chaque groupe ne sont pas toutes √©gales si p-value &lt; 5% Dans une ANOVA, on √©tudie la variance de chacun de ces groupes. Pour cela on utilise la fonction aov(). aov &lt;- aov(formula = Calories ~ Type, data = df) summary(aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Type 2 17692 8846 16.07 3.86e-06 *** ## Residuals 51 28067 550 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 H1 : Les moyennes de chaque groupe ne sont pas toutes √©gales Quand on dispose d‚Äôun petit √©chantillon, la pertinence de ce test repose sur la validation de plusieurs hypoth√®ses : l‚Äôind√©pendance entre les √©chantillons de chaque groupe l‚Äô√©galit√© des des variances que l‚Äôon peut verifier avec un test de Bartlett. la normal 2.3.1 L‚Äôind√©pendance L‚Äôind√©pendance est une des 3 conditions de validit√© d‚Äôune ANOVA. Seul le contexte de l‚Äô√©tude permet de s‚Äôassurer de l‚Äôind√©pendance entre les √©chantillons de chaque groupe (ici beef, poultry, chicken.) 2.3.2 L‚Äô√©galit√© des variances On parle aussi d‚Äôhomosc√©dasticit√©. C‚Äôest une des 3 conditions de validit√© d‚Äôune ANOVA. On cherche √† d√©montrer que les variances de chaque groupe sont √©gales. Dans un boxplot, l‚Äôamplitude des bo√Ætes traduit graphiquement l‚Äô√©galit√© des variances. boxplot(Calories ~ Type, data = df, horizontal = TRUE) Mais c‚Äôest le test de bartlett qui permet de tester si les variances sont significativement diff√©rentes ou non avec : H0 : Les variances de chaque groupe sont √©gales si p-value &gt; 5% H1 : Les variances de chaque groupe ne sont pas toutes √©gales &lt; 5% bartlett.test(Calories ~ Type, data = df) ## ## Bartlett test of homogeneity of variances ## ## data: Calories by Type ## Bartlett&#39;s K-squared = 0.26732, df = 2, p-value = 0.8749 H0 : Les variances de chaque groupe sont √©gales. La deuxi√®me condition pour effectuer une anova est valid√©e. 2.3.3 Normalit√© des r√©sidus C‚Äôest une des 3 conditions de validit√© d‚Äôune ANOVA. L‚Äôobjectif est de s‚Äôassurer que les r√©sidus suivent une loi normale afin de ne pas affirmer qu‚Äôil existe une diff√©rence de moyenne entre les groupes qui serait caus√©e par le hasard. Dans R, on utilise le test de Shapiro-Wilk pour tester la normalit√© des r√©sidus o√π : H0 : Les r√©sidus suivent une loi normale si p-value &gt; 5% H1 : Les r√©sidus ne suivent pas une loi normale si p-value &lt; 5% aov &lt;- aov(formula = Calories ~ Type, data = df) shapiro.test(aov$residuals) ## ## Shapiro-Wilk normality test ## ## data: aov$residuals ## W = 0.94199, p-value = 0.0113 H1 : Les r√©sidus ne suivent pas une loi normale 2.3.4 Calcul - Cas des variances √©gales a &lt;- seq(from = 1, to = 11, length.out = 9 ) b &lt;- seq(from = 31, to = 40, length.out = 9 ) c &lt;- seq(from = 51, to = 62, length.out = 9 ) df &lt;- data.frame(Valeur = c(a,b,c), Groupe = c(rep(&quot;A&quot;,9), rep(&quot;B&quot;,9), rep(&quot;C&quot;,9))) head(df) ## Valeur Groupe ## 1 1.00 A ## 2 2.25 A ## 3 3.50 A ## 4 4.75 A ## 5 6.00 A ## 6 7.25 A boxplot(Valeur ~ Groupe, data = df, col = 1:3, horizontal = TRUE) Comment calculer le tableau r√©captitulatif de l‚Äôanalyse de la variance : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Groupe 2 11585 5792 491 &lt;2e-16 *** ## Residuals 24 283 12 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Variance intra classes SCE_a &lt;- (a - mean(a))^2 SCE_b &lt;- (b - mean(b))^2 SCE_c &lt;- (c - mean(c))^2 intra &lt;- sum(SCE_a + SCE_b + SCE_c) intra ## [1] 283.125 Variance inter classes moyenne &lt;- mean(df$Valeur) moyenne_facteur &lt;- tapply(X = df$Valeur, INDEX = df$Groupe, FUN = mean) longueur_facteur &lt;- tapply(X = df$Valeur, INDEX = df$Groupe, FUN = length) inter &lt;- sum(longueur_facteur*((moyenne_facteur - moyenne)^2)) inter ## [1] 11584.5 Degr√© de libert√© n &lt;- nrow(df) p &lt;- length(levels(df$Groupe)) dof_inter &lt;- p - 1 dof_intra &lt;- n - p dof_inter ## [1] 2 dof_intra ## [1] 24 Calcul de la statistique de test de Fisher Stat_Fisher &lt;- (inter/dof_inter) / (intra/dof_intra) Stat_Fisher ## [1] 490.9987 On lit dans la table de Fisher pvalue &lt;- 1-pf(q = Stat_Fisher, df1 = dof_inter, df2 = dof_intra) pvalue ## [1] 0 R√©ciproque de la loi de Fisher pour retrouver la statistique de test. qf(p = 1-pvalue, df1 = dof_inter, df2 = dof_intra) ## [1] Inf 2.3.5 Calcul - Cas des variances in√©gales a &lt;- seq(from = 1, to = 40, length.out = 9 ) b &lt;- seq(from = 10, to = 30, length.out = 9 ) c &lt;- seq(from = 25, to = 30, length.out = 9 ) df &lt;- data.frame(Valeur = c(a,b,c), Groupe = c(rep(&quot;A&quot;,9), rep(&quot;B&quot;,9), rep(&quot;C&quot;,9))) head(df) ## Valeur Groupe ## 1 1.000 A ## 2 5.875 A ## 3 10.750 A ## 4 15.625 A ## 5 20.500 A ## 6 25.375 A boxplot(Valeur ~ Groupe, data = df, col = 1:3, horizontal = TRUE) Comment calculer le tableau r√©captitulatif de l‚Äôanalyse de la variance : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Groupe 2 316.5 158.25 2.082 0.147 ## Residuals 24 1824.4 76.02 Variance intra classes SCE_a &lt;- (a - mean(a))^2 SCE_b &lt;- (b - mean(b))^2 SCE_c &lt;- (c - mean(c))^2 intra &lt;- sum(SCE_a + SCE_b + SCE_c) intra ## [1] 1824.375 Variance inter classes moyenne &lt;- mean(df$Valeur) moyenne_facteur &lt;- tapply(X = df$Valeur, INDEX = df$Groupe, FUN = mean) longueur_facteur &lt;- tapply(X = df$Valeur, INDEX = df$Groupe, FUN = length) inter &lt;- sum(longueur_facteur*((moyenne_facteur - moyenne)^2)) inter ## [1] 316.5 Degr√© de libert√© n &lt;- nrow(df) p &lt;- length(levels(df$Groupe)) dof_inter &lt;- p - 1 dof_intra &lt;- n - p dof_inter ## [1] 2 dof_intra ## [1] 24 Calcul de la statistique de test de Fisher Stat_Fisher &lt;- (inter/dof_inter) / (intra/dof_intra) Stat_Fisher ## [1] 2.081809 On lit dans la table de Fisher pvalue &lt;- 1-pf(q = Stat_Fisher, df1 = dof_inter, df2 = dof_intra) pvalue ## [1] 0.1466471 R√©ciproque de la loi de Fisher pour retrouver la statistique de test. qf(p = 1-pvalue, df1 = dof_inter, df2 = dof_intra) ## [1] 2.081809 2.4 ANOVA 2 M√™me principe que l‚ÄôAnova √† un facteur sauf qu‚Äôon ajoute un autre facteur. L‚Äôid√©e est de tester l‚Äôind√©pendance de ces facteurs sur une variable quantitatives continue. On √©tudie la longueur des odontoblastes (cellules responsables de la croissance dentaire) chez 60 cobayes. Chaque animal a re√ßu l‚Äôune des trois doses de vitamine C (0,5, 1 et 2 mg / jour) par l‚Äôune des deux m√©thodes d‚Äôadministration, du jus d‚Äôorange ou de l‚Äôacide ascorbique (une forme de vitamine C et cod√©e VC) : len : lLongueur de la dent supp : suppl√©ment (VC ou OJ). dose : dose en milligrammes / jour Ce jeu de donn√©es ToothGrowth est pr√©sent dans le datasets. df &lt;- ToothGrowth len supp dose 4.2 VC 0.5 11.5 VC 0.5 7.3 VC 0.5 5.8 VC 0.5 6.4 VC 0.5 10.0 VC 0.5 11.2 VC 0.5 11.2 VC 0.5 5.2 VC 0.5 7.0 VC 0.5 16.5 VC 1.0 16.5 VC 1.0 15.2 VC 1.0 17.3 VC 1.0 22.5 VC 1.0 17.3 VC 1.0 13.6 VC 1.0 14.5 VC 1.0 18.8 VC 1.0 15.5 VC 1.0 23.6 VC 2.0 18.5 VC 2.0 33.9 VC 2.0 25.5 VC 2.0 26.4 VC 2.0 32.5 VC 2.0 26.7 VC 2.0 21.5 VC 2.0 23.3 VC 2.0 29.5 VC 2.0 15.2 OJ 0.5 21.5 OJ 0.5 17.6 OJ 0.5 9.7 OJ 0.5 14.5 OJ 0.5 10.0 OJ 0.5 8.2 OJ 0.5 9.4 OJ 0.5 16.5 OJ 0.5 9.7 OJ 0.5 19.7 OJ 1.0 23.3 OJ 1.0 23.6 OJ 1.0 26.4 OJ 1.0 20.0 OJ 1.0 25.2 OJ 1.0 25.8 OJ 1.0 21.2 OJ 1.0 14.5 OJ 1.0 27.3 OJ 1.0 25.5 OJ 2.0 26.4 OJ 2.0 22.4 OJ 2.0 24.5 OJ 2.0 24.8 OJ 2.0 30.9 OJ 2.0 26.4 OJ 2.0 27.3 OJ 2.0 29.4 OJ 2.0 23.0 OJ 2.0 En th√©orie, dans une ANOVA √† plusieurs facteurs, il faut valider chacune des hypoth√®ses une √† une pour chaque facteur. La particularit√© de l‚ÄôANOVA √† plusieurs facteurs r√©side dans la mesure de l‚Äôint√©raction entre les facteurs pouvant mener √† des diff√©rences de moyennes entres les groupes. 2.4.1 Effet de la variable supp boxplot(len ~ supp, data = df, horizontal = TRUE) 2.4.2 Effet de la variable dose boxplot(len ~ dose, data = df, horizontal = TRUE) 2.4.3 Effet l‚Äôint√©raction entre les deux facteurs Pour visualiser graphiquement l‚Äôint√©raction, on cr√©e une colonne avec les deux modalit√©s df$interaction &lt;- paste(df$supp,&quot;-&quot;,df$dose) boxplot(len ~ interaction, data = df, horizontal = TRUE) 2.4.4 Calcul de l‚ÄôANOVA 2 Quelques soit le nombre de facteurs √©tudi√©s, nous avons toujours les m√™mes hypoth√®ses dans une ANOVA : H0 : Les moyennes de chaque groupe sont √©gales si p-value &gt; 5% H1 : Les moyennes de chaque groupe ne sont pas toutes √©gales si p-value &lt; 5% df$dose &lt;- as.factor(df$dose) aov &lt;- aov(formula = len ~ dose + supp + supp*dose , data = df) summary(aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## dose 2 2426.4 1213.2 92.000 &lt; 2e-16 *** ## supp 1 205.4 205.4 15.572 0.000231 *** ## dose:supp 2 108.3 54.2 4.107 0.021860 * ## Residuals 54 712.1 13.2 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 H1 : Les moyennes de chaque groupe ne sont pas toutes √©gales pour chaque facteur. üì¢ On voit donc qu‚Äôil existe une int√©raction entre les deux variables. Pour mesurer quelles associations sont significativement diff√©rentes des autres, on peut utilise un test de Tukey qui consiste √† faire des tests de comparaison de moyenne sur deux √©chantillon avec toutes les combinaisons d‚Äôassociation TukeyHSD(aov) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = len ~ dose + supp + supp * dose, data = df) ## ## $dose ## diff lwr upr p adj ## 1-0.5 9.130 6.362488 11.897512 0.0e+00 ## 2-0.5 15.495 12.727488 18.262512 0.0e+00 ## 2-1 6.365 3.597488 9.132512 2.7e-06 ## ## $supp ## diff lwr upr p adj ## VC-OJ -3.7 -5.579828 -1.820172 0.0002312 ## ## $`dose:supp` ## diff lwr upr p adj ## 1:OJ-0.5:OJ 9.47 4.671876 14.2681238 0.0000046 ## 2:OJ-0.5:OJ 12.83 8.031876 17.6281238 0.0000000 ## 0.5:VC-0.5:OJ -5.25 -10.048124 -0.4518762 0.0242521 ## 1:VC-0.5:OJ 3.54 -1.258124 8.3381238 0.2640208 ## 2:VC-0.5:OJ 12.91 8.111876 17.7081238 0.0000000 ## 2:OJ-1:OJ 3.36 -1.438124 8.1581238 0.3187361 ## 0.5:VC-1:OJ -14.72 -19.518124 -9.9218762 0.0000000 ## 1:VC-1:OJ -5.93 -10.728124 -1.1318762 0.0073930 ## 2:VC-1:OJ 3.44 -1.358124 8.2381238 0.2936430 ## 0.5:VC-2:OJ -18.08 -22.878124 -13.2818762 0.0000000 ## 1:VC-2:OJ -9.29 -14.088124 -4.4918762 0.0000069 ## 2:VC-2:OJ 0.08 -4.718124 4.8781238 1.0000000 ## 1:VC-0.5:VC 8.79 3.991876 13.5881238 0.0000210 ## 2:VC-0.5:VC 18.16 13.361876 22.9581238 0.0000000 ## 2:VC-1:VC 9.37 4.571876 14.1681238 0.0000058 en cours de r√©daction ‚Ä¶ "]
]
