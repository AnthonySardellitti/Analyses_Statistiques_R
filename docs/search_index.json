[
["index.html", "La data science avec R Chapitre 1 Pr√©face", " La data science avec R Anthony SARDELLITTI 2021-02-04 Chapitre 1 Pr√©face Ce livre permet de mettre un pied dans le monde de la data science avec le langage R. Il pr√©sente les concepts fondamentaux √† travers la Statistique et les approches de Machine Learning (r√©alisation en cours). Le code source de ce cours est disponible sur github. "],
["independance.html", "Chapitre 2 Test ind√©pendance 2.1 Test de corr√©lation 2.2 Test du CHI¬≤ 2.3 ANOVA 1 2.4 ANOVA 2", " Chapitre 2 Test ind√©pendance Les tests d‚Äôind√©pendances permettent de d√©finir s‚Äôil existe un lien entre deux variables. Il existe diff√©rent test d‚Äôind√©pence, en voici quelques exemples : Test ind√©pendance entre deux variables quantitatives / Test de corr√©lation Pearson Test d‚Äôind√©pendance entre deux variables qualitatives / Test du Chi¬≤ Test d‚Äôind√©pendance entre une variable qualitative et une quantitative / Test de Fisher avec l‚Äôanalyse de la variance (ANOVA) 2.1 Test de corr√©lation L‚Äôint√©r√™t des tests de corr√©lation est d‚Äôapporter plus de pertinence et fiabilit√© aux coefficients de corr√©lation. Il existe diff√©rents test de corr√©lation, nous utilisons celui de Pearson. On travaille avec le jeu de donn√©es fromage üßÄ df &lt;- read.csv(file = &quot;./datasets/fromage.txt&quot;, sep = &quot;\\t&quot;, row.names = 1) calories sodium calcium lipides retinol folates proteines cholesterol magnesium CarredelEst 314 353.5 72.6 26.3 51.6 30.3 21.0 70 20 Babybel 314 238.0 209.8 25.1 63.7 6.4 22.6 70 27 Beaufort 401 112.0 259.4 33.3 54.9 1.2 26.6 120 41 Bleu 342 336.0 211.1 28.9 37.1 27.5 20.2 90 27 Camembert 264 314.0 215.9 19.5 103.0 36.4 23.4 60 20 Cantal 367 256.0 264.0 28.8 48.8 5.7 23.0 90 30 plot(df) library(corrplot) corrplot(cor(df, method = &quot;pearson&quot;)) On pose les hypoth√®ses de d√©part : H0 : Variables ind√©pendantes si p-value &gt; 5% H1 : Variables non ind√©pendantes si p-value &lt; 5% 2.1.1 Lipide vs Magnesium La premi√®re sortie correspond au coefficient de corr√©lation, la seconde √† la p-value (ou probabilit√© critique) cor(x = df$lipides, y = df$magnesium) ## [1] 0.6898601 cor.test(x = df$lipides, y = df$magnesium) ## ## Pearson&#39;s product-moment correlation ## ## data: df$lipides and df$magnesium ## t = 4.9515, df = 27, p-value = 3.469e-05 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4327766 0.8431785 ## sample estimates: ## cor ## 0.6898601 H1 : Variables non ind√©pendantes 2.1.2 Sodium vs Retinol cor.test(x = df$sodium, y = df$retinol) ## ## Pearson&#39;s product-moment correlation ## ## data: df$sodium and df$retinol ## t = 0.75788, df = 27, p-value = 0.4551 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.2345870 0.4851693 ## sample estimates: ## cor ## 0.1443276 H0 : Variables ind√©pendantes si p-value &gt; 5% Si on veut rejeter H0 et prendre H1, j‚Äôai 45,5% de chance de me tromper Les tests statistiques sont tr√©s sensibles √† la taille de l‚Äô√©chantillon. Un coefficient de corr√©lation de 0.14 n‚Äôaura pas la m√™me significativit√© sur un √©chantillon de 29 fromages qu‚Äôun √©chantillon de 319 fromages avec le m√™me coefficient de corr√©lation. On construit un dataframe en dupliquant le nombre de lignes sodium &lt;- rep(df$sodium,times = 10) retinol &lt;- rep(df$retinol,times = 10) nom &lt;- rep(rownames(df),times = 10) df_10 &lt;- data.frame(nom,sodium,retinol) Chaque fromage appara√Æt plusieurs fois, on a augment√© la taille de l‚Äô√©chantillon table(df_10$nom) ## ## Babybel Beaufort Bleu ## 10 10 10 ## Camembert Cantal CarredelEst ## 10 10 10 ## Chabichou Chaource Cheddar ## 10 10 10 ## Comte Coulomniers Edam ## 10 10 10 ## Emmental Fr.chevrepatemolle Fr.fondu.45 ## 10 10 10 ## Fr.frais20nat. Fr.frais40nat. Maroilles ## 10 10 10 ## Morbier Parmesan Petitsuisse40 ## 10 10 10 ## PontlEveque Pyrenees Reblochon ## 10 10 10 ## Rocquefort SaintPaulin Tome ## 10 10 10 ## Vacherin Yaourtlaitent.nat. ## 10 10 On effectue un autre test de corr√©lation avec les m√™mes variables sur l‚Äô√©chantillon plus grand. cor.test(x = df_10$sodium, y = df_10$retinol) ## ## Pearson&#39;s product-moment correlation ## ## data: df_10$sodium and df_10$retinol ## t = 2.4752, df = 288, p-value = 0.01389 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.0296407 0.2552637 ## sample estimates: ## cor ## 0.1443276 H1 : Variables non ind√©pendantes On obtient logiquement le m√™me coefficient de corr√©lation, mais en revanche, cette fois si la p-value est proche de 0. 2.1.3 Matrice des p-values On effectue un test de corr√©lation sur chaque variable 2 √† 2 en isolant uniquement la p-value get_pvalue &lt;- function(x,y){ p &lt;- cor.test(df[,x],df[,y])$p.value return(p) } colonne &lt;- colnames(df) ligne &lt;- colnames(df) df_pvalues &lt;- outer(X = colonne, Y = ligne, FUN = Vectorize(get_pvalue)) colnames(df_pvalues) &lt;- colnames(df) rownames(df_pvalues) &lt;- colnames(df) On affiche la matrice des corr√©lations avec un gradiant de couleur corrplot(df_pvalues, cl.lim=c(0,1), method=&quot;number&quot;, type=&quot;upper&quot;, col=colorRampPalette(c(&quot;white&quot;,&quot;white&quot;,&quot;red&quot;,&quot;yellow&quot;,&quot;green&quot;))(20)) 2.1.4 Cas de relation non lin√©aire Les diff√©rents de corr√©lation sont beaucoup plus adapt√©s aux relation lin√©aire. C‚Äôest pourquoi il est important de toujours visualiser les distributions (plus d‚Äôinfos ici). Cas d‚Äôune relation non-lin√©aire et non-monotone x &lt;- -10:10 y &lt;- x^2 + rnorm(n = length(x)) plot(x,y) cor.test(x, y, method = &quot;pearson&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: x and y ## t = -0.0059598, df = 19, p-value = 0.9953 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.4327986 0.4305736 ## sample estimates: ## cor ## -0.001367272 cor.test(x, y, method = &quot;spearman&quot;) ## ## Spearman&#39;s rank correlation rho ## ## data: x and y ## S = 1506, p-value = 0.9258 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.02207792 cor.test(x, y, method = &quot;kendall&quot;) ## ## Kendall&#39;s rank correlation tau ## ## data: x and y ## T = 107, p-value = 0.9287 ## alternative hypothesis: true tau is not equal to 0 ## sample estimates: ## tau ## 0.01904762 2.2 Test du CHI¬≤ L‚Äôint√©r√™t du test du Chi¬≤ est de mesurer l‚Äôind√©pendance entre deux variables qualitatives √† partir de tableau de contigence. 2.2.1 Titanic On travaille sur le jeu de donn√©es Titanic üßä‚õ¥ df &lt;- read.csv(file = &quot;./datasets/Titanic.csv&quot;, row.names = 1) Name PClass Age Sex Survived SexCode Allen, Miss Elisabeth Walton 1st 29.00 female 1 1 Allison, Miss Helen Loraine 1st 2.00 female 0 1 Allison, Mr Hudson Joshua Creighton 1st 30.00 male 0 0 Allison, Mrs Hudson JC (Bessie Waldo Daniels) 1st 25.00 female 0 1 Allison, Master Hudson Trevor 1st 0.92 male 1 0 Anderson, Mr Harry 1st 47.00 male 1 0 df_count &lt;- table(df$Survived, df$PClass) On pose : H0 : Variables ind√©pendantes si p-value &gt; 5% H1 : Variables non ind√©pendantes si p-value &lt; 5% resultat &lt;-chisq.test(df$Survived,df$PClass) resultat ## ## Pearson&#39;s Chi-squared test ## ## data: df$Survived and df$PClass ## X-squared = 172.3, df = 2, p-value &lt; 2.2e-16 H1 : Variables non ind√©pendantes La fonction attributes permet d‚Äôafficher les diff√©rentes sorties calcul√©es. attributes(resultat) ## $names ## [1] &quot;statistic&quot; &quot;parameter&quot; &quot;p.value&quot; &quot;method&quot; &quot;data.name&quot; &quot;observed&quot; ## [7] &quot;expected&quot; &quot;residuals&quot; &quot;stdres&quot; ## ## $class ## [1] &quot;htest&quot; Par exemple le tableau des effectifs th√©oriques. resultat$expected ## df$PClass ## df$Survived 1st 2nd 3rd ## 0 211.642 184.03656 467.3214 ## 1 110.358 95.96344 243.6786 2.2.2 Exemple du support data &lt;- matrix(rbind(c(693,886,534,153),c(597,696,448,95)),ncol=4) data ## [,1] [,2] [,3] [,4] ## [1,] 693 886 534 153 ## [2,] 597 696 448 95 chisq.test(data) ## ## Pearson&#39;s Chi-squared test ## ## data: data ## X-squared = 6.0504, df = 3, p-value = 0.1092 H0 : Variables ind√©pendantes Si on veut rejeter H0 et prendre H1, j‚Äôai 10,9% de chance de me tromper Lecture dans la table du Chi2 p &lt;- seq(0.80, 0.90, 0.005) dof &lt;- seq(1,3) chisq_table &lt;- outer(p, dof, function(x,y) qchisq(x,y)) chisq_table &lt;- t(chisq_table) colnames(chisq_table) &lt;- 1 - p rownames(chisq_table) &lt;- dof chisq_table &lt;- round(chisq_table,2) 0.2 0.195 0.19 0.185 0.18 0.175 0.17 0.165 0.16 0.155 0.15 0.145 0.14 0.135 0.13 0.125 0.12 0.115 0.11 0.105 0.1 1 1.64 1.68 1.72 1.76 1.80 1.84 1.88 1.93 1.97 2.02 2.07 2.12 2.18 2.23 2.29 2.35 2.42 2.48 2.55 2.63 2.71 2 3.22 3.27 3.32 3.37 3.43 3.49 3.54 3.60 3.67 3.73 3.79 3.86 3.93 4.00 4.08 4.16 4.24 4.33 4.41 4.51 4.61 3 4.64 4.70 4.76 4.83 4.89 4.96 5.02 5.09 5.17 5.24 5.32 5.40 5.48 5.56 5.65 5.74 5.83 5.93 6.03 6.14 6.25 üì¢ Taille de l‚Äô√©chantillon Les tests d‚Äôind√©pendance sont tr√©s sensibles √† la taille des √©chantillons. Ici on divise par 100 pour avoir des effectifs faibles mais en conservant les r√©partitions. chisq.test(data/100) ## ## Pearson&#39;s Chi-squared test ## ## data: data/100 ## X-squared = 0.060504, df = 3, p-value = 0.9961 H0 : Variables ind√©pendantes Ici on multiplie par 100 pour avoir des effectifs grands mais en conservant les r√©partitions chisq.test(data*100) ## ## Pearson&#39;s Chi-squared test ## ## data: data * 100 ## X-squared = 605.04, df = 3, p-value &lt; 2.2e-16 H1 : Variables non ind√©pendantes 2.3 ANOVA 1 On effectue une analyse de variance pour mesurer l‚Äôind√©pendance entre une variable qualitative et une quantitative. Pour illustrer cela, on utilise le jeu de donn√©es Hotdogs üå≠. df &lt;- read.csv(file = &quot;./datasets/Hotdogs.csv&quot;, sep = &quot;;&quot;) Type Calories Sodium Beef 186 495 Beef 181 477 Beef 176 425 Beef 149 322 Beef 184 482 Beef 190 587 On va tester l‚Äôind√©pendance entre la variable qualitative Type et la variable quantitatives Calories. boxplot(Calories ~ Type, data = df, horizontal = TRUE) Dans une ANOVA, on cherche √† d√©terminer si les moyennes des groupes sont significativement diff√©rentes. On pose donc : H0 : Les moyennes de chaque groupe sont √©gales si p-value &gt; 5% H1 : Les moyennes de chaque groupe ne sont pas toutes √©gales si p-value &lt; 5% Dans une ANOVA, on √©tudie la variance de chacun de ces groupes. Pour cela on utilise la fonction aov(). aov &lt;- aov(formula = Calories ~ Type, data = df) summary(aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Type 2 17692 8846 16.07 3.86e-06 *** ## Residuals 51 28067 550 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 H1 : Les moyennes de chaque groupe ne sont pas toutes √©gales Quand on dispose d‚Äôun petit √©chantillon, la pertinence de ce test repose sur la validation de plusieurs hypoth√®ses : l‚Äôind√©pendance entre les √©chantillons de chaque groupe l‚Äô√©galit√© des des variances que l‚Äôon peut verifier avec un test de Bartlett. la normal 2.3.1 L‚Äôind√©pendance L‚Äôind√©pendance est une des 3 conditions de validit√© d‚Äôune ANOVA. Seul le contexte de l‚Äô√©tude permet de s‚Äôassurer de l‚Äôind√©pendance entre les √©chantillons de chaque groupe (ici beef, poultry, chicken.) 2.3.2 L‚Äô√©galit√© des variances On parle aussi d‚Äôhomosc√©dasticit√©. C‚Äôest une des 3 conditions de validit√© d‚Äôune ANOVA. On cherche √† d√©montrer que les variances de chaque groupe sont √©gales. Dans un boxplot, l‚Äôamplitude des bo√Ætes traduit graphiquement l‚Äô√©galit√© des variances. boxplot(Calories ~ Type, data = df, horizontal = TRUE) Mais c‚Äôest le test de bartlett qui permet de tester si les variances sont significativement diff√©rentes ou non avec : H0 : Les variances de chaque groupe sont √©gales si p-value &gt; 5% H1 : Les variances de chaque groupe ne sont pas toutes √©gales &lt; 5% bartlett.test(Calories ~ Type, data = df) ## ## Bartlett test of homogeneity of variances ## ## data: Calories by Type ## Bartlett&#39;s K-squared = 0.26732, df = 2, p-value = 0.8749 H0 : Les variances de chaque groupe sont √©gales. La deuxi√®me condition pour effectuer une anova est valid√©e. 2.3.3 Normalit√© des r√©sidus C‚Äôest une des 3 conditions de validit√© d‚Äôune ANOVA. L‚Äôobjectif est de s‚Äôassurer que les r√©sidus suivent une loi normale afin de ne pas affirmer qu‚Äôil existe une diff√©rence de moyenne entre les groupes qui serait caus√©e par le hasard. Dans R, on utilise le test de Shapiro-Wilk pour tester la normalit√© des r√©sidus o√π : H0 : Les r√©sidus suivent une loi normale si p-value &gt; 5% H1 : Les r√©sidus ne suivent pas une loi normale si p-value &lt; 5% aov &lt;- aov(formula = Calories ~ Type, data = df) shapiro.test(aov$residuals) ## ## Shapiro-Wilk normality test ## ## data: aov$residuals ## W = 0.94199, p-value = 0.0113 H1 : Les r√©sidus ne suivent pas une loi normale 2.3.4 Calcul - Cas des variances √©gales a &lt;- seq(from = 1, to = 11, length.out = 9 ) b &lt;- seq(from = 31, to = 40, length.out = 9 ) c &lt;- seq(from = 51, to = 62, length.out = 9 ) df &lt;- data.frame(Valeur = c(a,b,c), Groupe = c(rep(&quot;A&quot;,9), rep(&quot;B&quot;,9), rep(&quot;C&quot;,9))) head(df) ## Valeur Groupe ## 1 1.00 A ## 2 2.25 A ## 3 3.50 A ## 4 4.75 A ## 5 6.00 A ## 6 7.25 A boxplot(Valeur ~ Groupe, data = df, col = 1:3, horizontal = TRUE) Comment calculer le tableau r√©captitulatif de l‚Äôanalyse de la variance : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Groupe 2 11585 5792 491 &lt;2e-16 *** ## Residuals 24 283 12 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Variance intra classes SCE_a &lt;- (a - mean(a))^2 SCE_b &lt;- (b - mean(b))^2 SCE_c &lt;- (c - mean(c))^2 intra &lt;- sum(SCE_a + SCE_b + SCE_c) intra ## [1] 283.125 Variance inter classes moyenne &lt;- mean(df$Valeur) moyenne_facteur &lt;- tapply(X = df$Valeur, INDEX = df$Groupe, FUN = mean) longueur_facteur &lt;- tapply(X = df$Valeur, INDEX = df$Groupe, FUN = length) inter &lt;- sum(longueur_facteur*((moyenne_facteur - moyenne)^2)) inter ## [1] 11584.5 Degr√© de libert√© n &lt;- nrow(df) p &lt;- length(levels(df$Groupe)) dof_inter &lt;- p - 1 dof_intra &lt;- n - p dof_inter ## [1] 2 dof_intra ## [1] 24 Calcul de la statistique de test de Fisher Stat_Fisher &lt;- (inter/dof_inter) / (intra/dof_intra) Stat_Fisher ## [1] 490.9987 On lit dans la table de Fisher pvalue &lt;- 1-pf(q = Stat_Fisher, df1 = dof_inter, df2 = dof_intra) pvalue ## [1] 0 R√©ciproque de la loi de Fisher pour retrouver la statistique de test. qf(p = 1-pvalue, df1 = dof_inter, df2 = dof_intra) ## [1] Inf 2.3.5 Calcul - Cas des variances in√©gales a &lt;- seq(from = 1, to = 40, length.out = 9 ) b &lt;- seq(from = 10, to = 30, length.out = 9 ) c &lt;- seq(from = 25, to = 30, length.out = 9 ) df &lt;- data.frame(Valeur = c(a,b,c), Groupe = c(rep(&quot;A&quot;,9), rep(&quot;B&quot;,9), rep(&quot;C&quot;,9))) head(df) ## Valeur Groupe ## 1 1.000 A ## 2 5.875 A ## 3 10.750 A ## 4 15.625 A ## 5 20.500 A ## 6 25.375 A boxplot(Valeur ~ Groupe, data = df, col = 1:3, horizontal = TRUE) Comment calculer le tableau r√©captitulatif de l‚Äôanalyse de la variance : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Groupe 2 316.5 158.25 2.082 0.147 ## Residuals 24 1824.4 76.02 Variance intra classes SCE_a &lt;- (a - mean(a))^2 SCE_b &lt;- (b - mean(b))^2 SCE_c &lt;- (c - mean(c))^2 intra &lt;- sum(SCE_a + SCE_b + SCE_c) intra ## [1] 1824.375 Variance inter classes moyenne &lt;- mean(df$Valeur) moyenne_facteur &lt;- tapply(X = df$Valeur, INDEX = df$Groupe, FUN = mean) longueur_facteur &lt;- tapply(X = df$Valeur, INDEX = df$Groupe, FUN = length) inter &lt;- sum(longueur_facteur*((moyenne_facteur - moyenne)^2)) inter ## [1] 316.5 Degr√© de libert√© n &lt;- nrow(df) p &lt;- length(levels(df$Groupe)) dof_inter &lt;- p - 1 dof_intra &lt;- n - p dof_inter ## [1] 2 dof_intra ## [1] 24 Calcul de la statistique de test de Fisher Stat_Fisher &lt;- (inter/dof_inter) / (intra/dof_intra) Stat_Fisher ## [1] 2.081809 On lit dans la table de Fisher pvalue &lt;- 1-pf(q = Stat_Fisher, df1 = dof_inter, df2 = dof_intra) pvalue ## [1] 0.1466471 R√©ciproque de la loi de Fisher pour retrouver la statistique de test. qf(p = 1-pvalue, df1 = dof_inter, df2 = dof_intra) ## [1] 2.081809 2.4 ANOVA 2 M√™me principe que l‚ÄôAnova √† un facteur sauf qu‚Äôon ajoute un autre facteur. L‚Äôid√©e est de tester l‚Äôind√©pendance de ces facteurs sur une variable quantitatives continue. On √©tudie la longueur des odontoblastes (cellules responsables de la croissance dentaire) chez 60 cobayes. Chaque animal a re√ßu l‚Äôune des trois doses de vitamine C (0,5, 1 et 2 mg / jour) par l‚Äôune des deux m√©thodes d‚Äôadministration, du jus d‚Äôorange ou de l‚Äôacide ascorbique (une forme de vitamine C et cod√©e VC) : len : lLongueur de la dent supp : suppl√©ment (VC ou OJ). dose : dose en milligrammes / jour Ce jeu de donn√©es ToothGrowth est pr√©sent dans le datasets. df &lt;- ToothGrowth len supp dose 4.2 VC 0.5 11.5 VC 0.5 7.3 VC 0.5 5.8 VC 0.5 6.4 VC 0.5 10.0 VC 0.5 11.2 VC 0.5 11.2 VC 0.5 5.2 VC 0.5 7.0 VC 0.5 16.5 VC 1.0 16.5 VC 1.0 15.2 VC 1.0 17.3 VC 1.0 22.5 VC 1.0 17.3 VC 1.0 13.6 VC 1.0 14.5 VC 1.0 18.8 VC 1.0 15.5 VC 1.0 23.6 VC 2.0 18.5 VC 2.0 33.9 VC 2.0 25.5 VC 2.0 26.4 VC 2.0 32.5 VC 2.0 26.7 VC 2.0 21.5 VC 2.0 23.3 VC 2.0 29.5 VC 2.0 15.2 OJ 0.5 21.5 OJ 0.5 17.6 OJ 0.5 9.7 OJ 0.5 14.5 OJ 0.5 10.0 OJ 0.5 8.2 OJ 0.5 9.4 OJ 0.5 16.5 OJ 0.5 9.7 OJ 0.5 19.7 OJ 1.0 23.3 OJ 1.0 23.6 OJ 1.0 26.4 OJ 1.0 20.0 OJ 1.0 25.2 OJ 1.0 25.8 OJ 1.0 21.2 OJ 1.0 14.5 OJ 1.0 27.3 OJ 1.0 25.5 OJ 2.0 26.4 OJ 2.0 22.4 OJ 2.0 24.5 OJ 2.0 24.8 OJ 2.0 30.9 OJ 2.0 26.4 OJ 2.0 27.3 OJ 2.0 29.4 OJ 2.0 23.0 OJ 2.0 En th√©orie, dans une ANOVA √† plusieurs facteurs, il faut valider chacune des hypoth√®ses une √† une pour chaque facteur. La particularit√© de l‚ÄôANOVA √† plusieurs facteurs r√©side dans la mesure de l‚Äôint√©raction entre les facteurs pouvant mener √† des diff√©rences de moyennes entres les groupes. 2.4.1 Effet de la variable supp boxplot(len ~ supp, data = df, horizontal = TRUE) 2.4.2 Effet de la variable dose boxplot(len ~ dose, data = df, horizontal = TRUE) 2.4.3 Effet l‚Äôint√©raction entre les deux facteurs Pour visualiser graphiquement l‚Äôint√©raction, on cr√©e une colonne avec les deux modalit√©s df$interaction &lt;- paste(df$supp,&quot;-&quot;,df$dose) boxplot(len ~ interaction, data = df, horizontal = TRUE) 2.4.4 Calcul de l‚ÄôANOVA 2 Quelques soit le nombre de facteurs √©tudi√©s, nous avons toujours les m√™mes hypoth√®ses dans une ANOVA : H0 : Les moyennes de chaque groupe sont √©gales si p-value &gt; 5% H1 : Les moyennes de chaque groupe ne sont pas toutes √©gales si p-value &lt; 5% df$dose &lt;- as.factor(df$dose) aov &lt;- aov(formula = len ~ dose + supp + supp*dose , data = df) summary(aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## dose 2 2426.4 1213.2 92.000 &lt; 2e-16 *** ## supp 1 205.4 205.4 15.572 0.000231 *** ## dose:supp 2 108.3 54.2 4.107 0.021860 * ## Residuals 54 712.1 13.2 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 H1 : Les moyennes de chaque groupe ne sont pas toutes √©gales pour chaque facteur. üì¢ On voit donc qu‚Äôil existe une int√©raction entre les deux variables. Pour mesurer quelles associations sont significativement diff√©rentes des autres, on peut utilise un test de Tukey qui consiste √† faire des tests de comparaison de moyenne sur deux √©chantillon avec toutes les combinaisons d‚Äôassociation TukeyHSD(aov) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = len ~ dose + supp + supp * dose, data = df) ## ## $dose ## diff lwr upr p adj ## 1-0.5 9.130 6.362488 11.897512 0.0e+00 ## 2-0.5 15.495 12.727488 18.262512 0.0e+00 ## 2-1 6.365 3.597488 9.132512 2.7e-06 ## ## $supp ## diff lwr upr p adj ## VC-OJ -3.7 -5.579828 -1.820172 0.0002312 ## ## $`dose:supp` ## diff lwr upr p adj ## 1:OJ-0.5:OJ 9.47 4.671876 14.2681238 0.0000046 ## 2:OJ-0.5:OJ 12.83 8.031876 17.6281238 0.0000000 ## 0.5:VC-0.5:OJ -5.25 -10.048124 -0.4518762 0.0242521 ## 1:VC-0.5:OJ 3.54 -1.258124 8.3381238 0.2640208 ## 2:VC-0.5:OJ 12.91 8.111876 17.7081238 0.0000000 ## 2:OJ-1:OJ 3.36 -1.438124 8.1581238 0.3187361 ## 0.5:VC-1:OJ -14.72 -19.518124 -9.9218762 0.0000000 ## 1:VC-1:OJ -5.93 -10.728124 -1.1318762 0.0073930 ## 2:VC-1:OJ 3.44 -1.358124 8.2381238 0.2936430 ## 0.5:VC-2:OJ -18.08 -22.878124 -13.2818762 0.0000000 ## 1:VC-2:OJ -9.29 -14.088124 -4.4918762 0.0000069 ## 2:VC-2:OJ 0.08 -4.718124 4.8781238 1.0000000 ## 1:VC-0.5:VC 8.79 3.991876 13.5881238 0.0000210 ## 2:VC-0.5:VC 18.16 13.361876 22.9581238 0.0000000 ## 2:VC-1:VC 9.37 4.571876 14.1681238 0.0000058 en cours de r√©daction ‚Ä¶ "],
["entrainement.html", "Chapitre 3 S‚Äôentrainer 3.1 TP1 3.2 TP2", " Chapitre 3 S‚Äôentrainer 3.1 TP1 Ce TP reprend quelques rappels de R. On utilise le fichier pokemon.xlsx qui d√©crit les statistiques des pokemon des deux premi√®res g√©n√©rations. Le fichier est issu du site Kaggle. Il a √©t√© adapt√© pour ce TP. Pour r√©aliser ce TP, t√©l√©charger le fichier en cliquant ici. Voici une description des donn√©es : pokedex_number : num√©ro du pokemon nom : nom du pokemon generation : le num√©ro de g√©n√©ration dont est issu le pokemon is_legendary : Oui / Non si le pokemon est l√©gendaire type : le type du pokemon weight_kg : le poids du pokemon en kg height_m : la taille du pokemon en m√®tre attack : la puissance d‚Äôattaque du pokemon defense : la puissance de d√©fense du pokemon speed : la vitesse du pokemon pokedex_number nom generation is_legendary type weight_kg height_m attack defense speed 1 Bulbizarre 1 Non grass 6.9 0.7 49 49 45 2 Herbizarre 1 Non grass 13.0 1.0 62 63 60 3 Florizarre 1 Non grass 100.0 2.0 100 123 80 4 Salameche 1 Non fire 8.5 0.6 52 43 65 5 Reptincel 1 Non fire 19.0 1.1 64 58 80 6 Dracaufeu 1 Non fire 90.5 1.7 104 78 100 7 Carapuce 1 Non water 9.0 0.5 48 65 43 8 Carabaffe 1 Non water 22.5 1.0 63 80 58 9 Tortank 1 Non water 85.5 1.6 103 120 78 10 Chenipan 1 Non bug 2.9 0.3 30 35 45 11 Chrysacier 1 Non bug 9.9 0.7 20 55 30 12 Papilusion 1 Non bug 32.0 1.1 45 50 70 13 Aspicot 1 Non bug 3.2 0.3 35 30 50 14 Coconfort 1 Non bug 10.0 0.6 25 50 35 15 Dardargnan 1 Non bug 29.5 1.0 150 40 145 16 Roucool 1 Non normal 1.8 0.3 45 40 56 17 Roucoups 1 Non normal 30.0 1.1 60 55 71 18 Roucarnage 1 Non normal 39.5 1.5 80 80 121 19 Rattata 1 Non normal NA NA 56 35 72 20 Rattatac 1 Non normal NA NA 71 70 77 Exercice 1 : Importer les donn√©es Importez le jeu de donn√©es pokemon.xlsx √† l‚Äôaide du package readxl. Combien de lignes, colonnes sont pr√©sentes dans ce dataset (utilisez les fonctions adapt√©es) ? Affichez le nom des colonnes. Affichez le type des colonnes avec la fonction adapt√©e. On souhaite analyser les variables generation, is_legendary, et type en tant que variables qualitatives. Modifier le type de ces variables pour les transformer en type factor. Combien de niveaux (levels) sont pr√©sents dans ces variables ? Affichez un r√©sum√© des donn√©es avec la fonction adapt√©e. Exercice 2 : Statistiques descriptives D√©terminer la moyenne de la variable weight_kg. D√©terminer la m√©diane de la variable weight_kg. D√©terminer les quartiles de la variable height_m. D√©terminer les d√©ciles de la variable height_m. D√©terminer la variance et l‚Äô√©cart-type de la variable weight_kg. D√©terminer un tri √† plat pour compter les effectifs des modalit√©s de chaque variable factor en triant chaque sortie par ordre d√©croissant. Exercice 3 : Tris et Selections Pour chaque question suivante, affectez le r√©sultat de la requ√™te dans un objet puis calculez sa dimension. Exemple : #Selectionnez les deux premi√®res colonnes du data frame requete_0 &lt;- pokemon[,1:2] dim(requete_0) ## [1] 251 2 S√©lectionnez la colonne nom et is_legendary. S√©lectionnez les 50 premi√®res lignes et les deux premi√®res colonnes. S√©lectionnez les 10 premi√®res lignes et toutes les colonnes. S√©lectionnez toutes les colonnes sauf la derni√®re. S√©lectionnez les colonnes 2,8,9 et 10. S√©lectionnez les lignes 20 √† 30 et 80 √† 100. Triez le dataset par ordre alphab√©tique et afficher le nom du pokemon dela premi√®re ligne. Triez le dataset par weight_kg en ordre d√©croissant, et afficher le nomdu pokemon de la premi√®re ligne Triez le dataset par attack en ordre d√©croissant puis par speed en ordre croissant, et afficher le nom des pokemons des 10 premi√®res lignes. Exercice 4 : Tris et Filtres Pour chaque question suivante, affectez le r√©sultat de la requ√™te dans un objet puis calculez sa dimension. Pour faciliter la lecture, s√©lectionnez la colonne nomet les colonnes concern√©es par le filtre. Exemple : #Selectionnez les pokemons de type feu requete_0 &lt;- pokemon[ pokemon$type == &quot;fire&quot;, c(&quot;nom&quot;,&quot;type&quot;)] dim(requete_0) ## [1] 20 2 Filtrez sur les pokemons qui ont 150 ou plus d‚Äôattack puis trier le r√©sultat par ordre d√©croissant d‚Äôattack. Filtrez sur les pokemons de type dragon,ghost,psychic et dark Filtrez sur les pokemons de type fire avec plus de 100 d‚Äôattack, puis trier le r√©sultat par ordre d√©croissant d‚Äôattack. Filtrez sur les pokemons qui ont entre 100 et 150 de speed. Les trier par speedd√©croissant. Filtrez sur les pokemons pesant plus de 250 kg et affichez le r√©sultat pour v√©rifier. Filtrez sur les pok√©mons qui ont des valeurs manquantes sur la variable height_m. Filtrez sur les pokemons qui ont des valeurs renseign√©es √† la fois pour la variable weight_kg et la variable height. Exercice 5 : Corr√©lation Analysez les coefficients de corr√©lations des variables quantitatives weight_kg, height_m, attack, defense, speed. Il est conseill√© d‚Äôutiliser la matrice des corr√©lations et la visualisation adapt√©e. Repr√©sentez graphiquement les 3 couples de variables avec les coefficients de corr√©lations les plus √©lev√©s. Effectuez un test d‚Äôind√©pendance sur le couple de variables avec le coefficient de corr√©lation le plus bas. N‚Äôoubliez pas de poser les hypoth√®ses. Effectuez un test d‚Äôind√©pendance sur le couple de variables avec le coefficient de corr√©lation le plus √©lev√©. N‚Äôoubliez pas de poser les hypoth√®ses. Exercice 6 : Anova Dupliquer le data frame avec uniquement les pokemons de type water, fire, et grass. D√©terminer s‚Äôil y a ind√©pendance entre ces type et l‚Äô attack. D√©terminer s‚Äôil y a ind√©pendance entre ces type et l‚Äô speed. D√©terminer s‚Äôil y a ind√©pendance entre ces type et l‚Äô weight_kg. D√©terminer s‚Äôil y a ind√©pendance entre ces type et l‚Äô height_m. D√©terminer s‚Äôil y a ind√©pendance entre ces type et l‚Äô defense. Le type et la generation ont-il une influence sur l‚Äôattack ? Exercice 7 : Clustering Avec la m√©thode des K-Means, construire un clustering en 3 classes d‚Äôapr√®s les variables quantitatives weight_kg, height_m, attack, defense, speed. Faire varier le nombre de classe pour d√©terminer le nombre de cluster le plus pertinent. Expliquer les classes en d√©crivant graphiquement les clusters identifi√©s. Avez-vous centr√© et r√©duit les donn√©es sur les questions a √† c ? Non ? Alors c‚Äôest reparti ! Il se peut que les clusters varient consid√©rablement. Proposer une autre segmentation avec une m√©thode de clustering hi√©rarchique On observe des pokemons atypiques qui faussent nos deux m√©thodes de segmentation. Essayez de les identifier avec une m√©thode de clustering par densit√© pour les exclures Apr√®s avoir exclus les outliers, on peut refaire une segmentation avec la m√©thode de votre choix. Expliquer les classes en d√©crivant graphiquement les clusters identifi√©s. Exercice 8 : ACP Construire une Analyse en Composantes Principales sur les variables quantitatives Afficher la r√©partition de variances expliqu√©es de chacun des axes. Combien d‚Äôaxes est-il pertinent de conserver ? Construire puis interpreter le cercle des corr√©lations. Projeter les coordonn√©es des individus sur les deux premiers axes. Quelles est la variable qui contribue le plus √† la cr√©ation du facteur 1, et du facteur 2 ? Quel est le pok√©mon qui contribue le plus √† la cr√©ation du facteur 1, et du facteur 2 ? Proposer un clustering hi√©rarchique bas√© sur les r√©sultat de l‚ÄôACP Expliquer les classes en d√©crivant graphiquement les clusters identifi√©s. 3.2 TP2 Dans ce TP, vous travaillerez sur le jeu de donn√©es NBA.csv qui d√©crit les tirs effectu√©s au cours de la saison 2014-2015 de NBA. Le fichier est issu du site Kaggle. Il a √©t√© adapt√© et modifi√© pour ce TP. Pour r√©aliser ce TP, t√©l√©charger le fichier en cliquant ici. Voici la pr√©sentation du jeu de donn√©es : GAME_ID : ID du match LOCATION : Lieu du match (Home / Away) GAME_RESULT : R√©sultat du match (Won / Lost) PERIOD : Num√©ro de quart-temps et prolongations √©ventuelles SHOT_CLOCK : Dur√©e de la possession de l‚Äô√©quipe au moment du tir DRIBBLES : Nombre de dribbles avant le tir TOUCH_TIME : Dur√©e de la possession du joueur avant le tir SHOT_DIST : Distance de tir en foot (1 foot = 0,30 m√®tre) PTS_TYPE : Tentative √† 2 ou 3 points (les lancers francs √† 1 point ne sont pas r√©pertori√©s) SHOT_RESULT : R√©sultat du tir (made / missed) CLOSE_DEF_DIST : Distance entre le tireur et le d√©fenseur le plus proche en foot (1 foot = 0,30 m√®tre) SHOOTER : Nom du tireur GAME_ID LOCATION GAME_RESULT PERIOD SHOT_CLOCK DRIBBLES TOUCH_TIME SHOT_DIST PTS_TYPE SHOT_RESULT CLOSE_DEF_DIST SHOOTER 21400899 A W 1 10.8 2 1.9 7.7 2 made 1.3 brian roberts 21400899 A W 1 3.4 0 0.8 28.2 3 missed 6.1 brian roberts 21400899 A W 1 NA 3 2.7 10.1 2 missed 0.9 brian roberts 21400899 A W 2 10.3 2 1.9 17.2 2 missed 3.4 brian roberts 21400899 A W 2 10.9 2 2.7 3.7 2 missed 1.1 brian roberts 21400899 A W 2 9.1 2 4.4 18.4 2 missed 2.6 brian roberts 21400899 A W 4 14.5 11 9.0 20.7 2 missed 6.1 brian roberts 21400899 A W 4 3.4 3 2.5 3.5 2 made 2.1 brian roberts 21400899 A W 4 12.4 0 0.8 24.6 3 missed 7.3 brian roberts 21400890 H W 2 17.4 0 1.1 22.4 3 missed 19.8 brian roberts 21400890 H W 2 16.0 8 7.5 24.5 3 missed 4.7 brian roberts 21400890 H W 4 12.1 14 11.9 14.6 2 made 1.8 brian roberts 21400890 H W 4 4.3 2 2.9 5.9 2 made 5.4 brian roberts 21400882 A W 4 4.4 0 0.8 26.4 3 missed 4.4 brian roberts 21400859 A L 1 6.8 0 0.5 22.8 3 missed 5.3 brian roberts 21400859 A L 2 6.4 3 2.7 24.7 3 made 5.6 brian roberts 21400859 A L 2 17.6 6 5.1 25.0 3 missed 5.4 brian roberts 21400859 A L 4 8.7 1 0.9 25.6 3 missed 5.1 brian roberts 21400859 A L 4 20.8 0 1.2 24.2 3 made 11.1 brian roberts 21400845 A W 1 17.5 2 2.2 25.4 3 missed 3.5 brian roberts Exercice 1 : Importer les donn√©es Importer le jeu de donn√©es NBA.csv. Combien de lignes, colonnes sont pr√©sentes dans ce dataset (utilisez les fonctions adapt√©es) ? Afficher le nom des colonnes. Afficher le type des colonnes avec la fonction adapt√©e. On souhaite analyser les variables LOCATION, GAME_RESULT, PERIOD, PTS_TYPE et SHOT_RESULT en tant que variables qualitatives. Modifier le type de ces variables pour les transformer en type factor. Afficher un r√©sum√© des donn√©es avec la fonction adapt√©e. Exercice 2 : Ind√©pendance Analyser les V de Cramer (fonction cramer.v() du package questionr) des variables qualitatives LOCATION, GAME_RESULT, PERIOD, PTS_TYPE et SHOT_RESULT. Il est conseill√© d‚Äôutiliser une matrice avec les diff√©rentes valeurs. Repr√©senter graphiquement les 2 couples de variables avec les V de Cramer les plus √©lev√©s. Effectuer un test d‚Äôind√©pendance sur le couple de variables avec le V de Cramer le plus bas. N‚Äôoublier pas de poser les hypoth√®ses. Effectuer un test d‚Äôind√©pendance sur le couple de variables avec le V de Cramer le plus √©lev√©. N‚Äôoublier pas de poser les hypoth√®ses. Construire la matrice des p-values des tests d‚Äôind√©pendance des variables LOCATION, GAME_RESULT, PERIOD, PTS_TYPE et SHOT_RESULT. Proposez Exercice 3 : R√©gression On cherche √† pr√©dire SHOT_DIST selon les variables SHOT_CLOCK, DRIBBLES, TOUCH_TIME, CLOSE_DEF_DIST. Dupliquer le dataset dans un autre objet avec uniquement les colonnes concern√©es. Construire un √©chantillon d‚Äôapprentissage et un √©chantillon test Construire une r√©gression lin√©aire Tester le mod√®le sur l‚Äô√©chantillon d‚Äôapprentissage Evaluer le mod√®le en calculant le score RMSE entre les valeurs observ√©es et les valeurs pr√©dites. Exercice 4 : Arbre de d√©cision Supprimer les colonnes GAME_ID, GAME_RESULT et SHOOTER. Construire un √©chantillon d‚Äôapprentissage et un √©chantillon test Construire un arbre de d√©cision qui pr√©dit si un tir va √™tre marqu√© selon les autres variables explicatives. Visualiser l‚Äôarbre de d√©cision Tester le mod√®le sur l‚Äô√©chantillon d‚Äôapprentissage Evaluer le mod√®le en calculant le taux de bonnes pr√©dictions score entre les valeurs observ√©es et les valeurs pr√©dites. "],
["all-dataset.html", "Chapitre 4 Jeux de donn√©es utilis√©s 4.1 Iris üå∫ 4.2 Fromages üßÄ 4.3 Hotdogs üå≠ 4.4 Pokemon üêæ 4.5 Titanic üßä‚õ¥ 4.6 ToothGrowth ü¶∑ 4.7 NBA üèÄ", " Chapitre 4 Jeux de donn√©es utilis√©s Ce chapitre pr√©sente les diff√©rents jeux de donn√©es utilis√©s dans ce livre. 4.1 Iris üå∫ Le jeu de donn√©es pr√©sente les caract√©ristiques de 3 esp√®ces de fleurs. Il est int√©gr√© au package datasets d√©j√† charg√© √† chaque ouverture de session dans RStudio. Voici la pr√©sentation du jeu de donn√©es : Sepal.Length : longueur du s√©pale Sepal.Width : largeur du s√©pale Petal.Length : longueur du p√©tale Petal.Width : largeur du p√©tale Species : l‚Äôesp√®ce de la fleur dim(iris) ## [1] 150 5 Voici un extrait du dataset : Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa 4.2 Fromages üßÄ Le dataset fromage.txt d√©crit les caract√©ristiques alimentaires de diff√©rents fromages. Voici la pr√©sentation du jeu de donn√©es : calories sodium calcium Calories lipides retinol folates proteines cholesterol magnesium fromage &lt;- read.delim(&quot;./datasets/fromage.txt&quot;, row.names=1) dim(fromage) ## [1] 29 9 calories sodium calcium lipides retinol folates proteines cholesterol magnesium CarredelEst 314 353.5 72.6 26.3 51.6 30.3 21.0 70 20 Babybel 314 238.0 209.8 25.1 63.7 6.4 22.6 70 27 Beaufort 401 112.0 259.4 33.3 54.9 1.2 26.6 120 41 Bleu 342 336.0 211.1 28.9 37.1 27.5 20.2 90 27 Camembert 264 314.0 215.9 19.5 103.0 36.4 23.4 60 20 Cantal 367 256.0 264.0 28.8 48.8 5.7 23.0 90 30 Chabichou 344 192.0 87.2 27.9 90.1 36.3 19.5 80 36 Chaource 292 276.0 132.9 25.4 116.4 32.5 17.8 70 25 Cheddar 406 172.0 182.3 32.5 76.4 4.9 26.0 110 28 Comte 399 92.0 220.5 32.4 55.9 1.3 29.2 120 51 Coulomniers 308 222.0 79.2 25.6 63.6 21.1 20.5 80 13 Edam 327 148.0 272.2 24.7 65.7 5.5 24.7 80 44 Emmental 378 60.0 308.2 29.4 56.3 2.4 29.4 110 45 Fr.chevrepatemolle 206 160.0 72.8 18.5 150.5 31.0 11.1 50 16 Fr.fondu.45 292 390.0 168.5 24.0 77.4 5.5 16.8 70 20 Fr.frais20nat. 80 41.0 146.3 3.5 50.0 20.0 8.3 10 11 Fr.frais40nat. 115 25.0 94.8 7.8 64.3 22.6 7.0 30 10 Maroilles 338 311.0 236.7 29.1 46.7 3.6 20.4 90 40 Morbier 347 285.0 219.0 29.5 57.6 5.8 23.6 80 30 Parmesan 381 240.0 334.6 27.5 90.0 5.2 35.7 80 46 4.3 Hotdogs üå≠ Le dataset Hotdogs.csv d√©crit les caract√©ristiques alimentaires de diff√©rents Hotdogs. Voici la pr√©sentation du jeu de donn√©es : Type : type de viande Calories : le nombre de calories Sodium : la teneur en sodium Hotdogs &lt;- read.csv(&quot;./datasets/Hotdogs.csv&quot;, sep=&quot;;&quot;) dim(Hotdogs) ## [1] 54 3 Type Calories Sodium Beef 186 495 Beef 181 477 Beef 176 425 Beef 149 322 Beef 184 482 Beef 190 587 Beef 158 370 Beef 139 322 Beef 175 479 Beef 148 375 Beef 152 330 Beef 111 300 Beef 141 386 Beef 153 401 Beef 190 645 Beef 157 440 Beef 131 317 Beef 149 319 Beef 135 298 Beef 132 253 4.4 Pokemon üêæ Le dataset pokemon.xlsx d√©crit les statistiques des pokemon des deux premi√®res g√©n√©rations. Le fichier est issu du site Kaggle. Il a √©t√© adapt√© dans ce livre Voici la pr√©sentation du jeu de donn√©es : pokedex_number : num√©ro du pokemon nom : nom du pokemon generation : le num√©ro de g√©n√©ration dont est issu le pokemon is_legendary : Oui / Non si le pokemon est l√©gendaire type : le type du pokemon weight_kg : le poids du pokemon en kg height_m : la taille du pokemon en m√®tre attack : la puissance d‚Äôattaque du pokemon defense : la puissance de d√©fense du pokemon speed : la vitesse du pokemon library(readxl) pokemon &lt;- read_excel(path = &quot;./datasets/pokemon.xlsx&quot;, sheet = &quot;pokemon&quot;) dim(pokemon) ## [1] 251 10 pokedex_number nom generation is_legendary type weight_kg height_m attack defense speed 1 Bulbizarre 1 Non grass 6.9 0.7 49 49 45 2 Herbizarre 1 Non grass 13.0 1.0 62 63 60 3 Florizarre 1 Non grass 100.0 2.0 100 123 80 4 Salameche 1 Non fire 8.5 0.6 52 43 65 5 Reptincel 1 Non fire 19.0 1.1 64 58 80 6 Dracaufeu 1 Non fire 90.5 1.7 104 78 100 7 Carapuce 1 Non water 9.0 0.5 48 65 43 8 Carabaffe 1 Non water 22.5 1.0 63 80 58 9 Tortank 1 Non water 85.5 1.6 103 120 78 10 Chenipan 1 Non bug 2.9 0.3 30 35 45 11 Chrysacier 1 Non bug 9.9 0.7 20 55 30 12 Papilusion 1 Non bug 32.0 1.1 45 50 70 13 Aspicot 1 Non bug 3.2 0.3 35 30 50 14 Coconfort 1 Non bug 10.0 0.6 25 50 35 15 Dardargnan 1 Non bug 29.5 1.0 150 40 145 16 Roucool 1 Non normal 1.8 0.3 45 40 56 17 Roucoups 1 Non normal 30.0 1.1 60 55 71 18 Roucarnage 1 Non normal 39.5 1.5 80 80 121 19 Rattata 1 Non normal NA NA 56 35 72 20 Rattatac 1 Non normal NA NA 71 70 77 4.5 Titanic üßä‚õ¥ Le dataset Titanic.csv d√©crit les informations des passagers pr√©sents lors du naufrage du Titanic. Voici la pr√©sentation du jeu de donn√©es : Name : le nom du passager PClass : la classe du passager (1st,2nd ou 3rd) Age : l‚Äô√¢ge du passager Sex : le genre du passager Survived : 1 si le passager a surv√©cu SexCode : le genre du passager en binaire 0/1 Titanic &lt;- read.csv(&quot;./datasets/Titanic.csv&quot;, row.names=1) dim(Titanic) ## [1] 1313 6 Name PClass Age Sex Survived SexCode Allen, Miss Elisabeth Walton 1st 29.00 female 1 1 Allison, Miss Helen Loraine 1st 2.00 female 0 1 Allison, Mr Hudson Joshua Creighton 1st 30.00 male 0 0 Allison, Mrs Hudson JC (Bessie Waldo Daniels) 1st 25.00 female 0 1 Allison, Master Hudson Trevor 1st 0.92 male 1 0 Anderson, Mr Harry 1st 47.00 male 1 0 Andrews, Miss Kornelia Theodosia 1st 63.00 female 1 1 Andrews, Mr Thomas, jr 1st 39.00 male 0 0 Appleton, Mrs Edward Dale (Charlotte Lamson) 1st 58.00 female 1 1 Artagaveytia, Mr Ramon 1st 71.00 male 0 0 Astor, Colonel John Jacob 1st 47.00 male 0 0 Astor, Mrs John Jacob (Madeleine Talmadge Force) 1st 19.00 female 1 1 Aubert, Mrs Leontine Pauline 1st NA female 1 1 Barkworth, Mr Algernon H 1st NA male 1 0 Baumann, Mr John D 1st NA male 0 0 Baxter, Mrs James (Helene DeLaudeniere Chaput) 1st 50.00 female 1 1 Baxter, Mr Quigg Edmond 1st 24.00 male 0 0 Beattie, Mr Thomson 1st 36.00 male 0 0 Beckwith, Mr Richard Leonard 1st 37.00 male 1 0 Beckwith, Mrs Richard Leonard (Sallie Monypeny) 1st 47.00 female 1 1 4.6 ToothGrowth ü¶∑ Ce jeu de donn√©es est pr√©sent dans le datasets. On √©tudie la longueur des odontoblastes (cellules responsables de la croissance dentaire) chez 60 cobayes. Chaque animal a re√ßu l‚Äôune des trois doses de vitamine C (0,5, 1 et 2 mg / jour) par l‚Äôune des deux m√©thodes d‚Äôadministration, du jus d‚Äôorange ou de l‚Äôacide ascorbique (une forme de vitamine C et cod√©e VC) : Voici la pr√©sentation du jeu de donn√©es : len : lLongueur de la dent supp : suppl√©ment (VC ou OJ). dose : dose en milligrammes / jour dim(ToothGrowth) ## [1] 60 3 len supp dose 4.2 VC 0.5 11.5 VC 0.5 7.3 VC 0.5 5.8 VC 0.5 6.4 VC 0.5 10.0 VC 0.5 11.2 VC 0.5 11.2 VC 0.5 5.2 VC 0.5 7.0 VC 0.5 16.5 VC 1.0 16.5 VC 1.0 15.2 VC 1.0 17.3 VC 1.0 22.5 VC 1.0 17.3 VC 1.0 13.6 VC 1.0 14.5 VC 1.0 18.8 VC 1.0 15.5 VC 1.0 4.7 NBA üèÄ Ce jeu de donn√©es NBA.csv d√©crit les tirs effectu√©s au cours de la saison 2014-2015 de NBA. Le fichier est issu du site Kaggle. Il a √©t√© adapt√© et modifi√©. Voici la pr√©sentation du jeu de donn√©es : GAME_ID : ID du match LOCATION : Lieu du match (Home / Away) GAME_RESULT : R√©sultat du match (Won / Lost) PERIOD : Num√©ro de quart-temps et prolongations √©ventuelles SHOT_CLOCK : Dur√©e de la possession de l‚Äô√©quipe au moment du tir DRIBBLES : Nombre de dribbles avant le tir TOUCH_TIME : Dur√©e de la possession du joueur avant le tir SHOT_DIST : Distance de tir en foot (1 foot = 0,30 m√®tre) PTS_TYPE : Tentative √† 2 ou 3 points (les lancers francs √† 1 point ne sont pas r√©pertori√©s) SHOT_RESULT : R√©sultat du tir (made / missed) CLOSE_DEF_DIST : Distance entre le tireur et le d√©fenseur le plus proche en foot (1 foot = 0,30 m√®tre) SHOOTER : Nom du tireur dim(NBA) ## [1] 128069 12 GAME_ID LOCATION GAME_RESULT PERIOD SHOT_CLOCK DRIBBLES TOUCH_TIME SHOT_DIST PTS_TYPE SHOT_RESULT CLOSE_DEF_DIST SHOOTER 21400899 A W 1 10.8 2 1.9 7.7 2 made 1.3 brian roberts 21400899 A W 1 3.4 0 0.8 28.2 3 missed 6.1 brian roberts 21400899 A W 1 NA 3 2.7 10.1 2 missed 0.9 brian roberts 21400899 A W 2 10.3 2 1.9 17.2 2 missed 3.4 brian roberts 21400899 A W 2 10.9 2 2.7 3.7 2 missed 1.1 brian roberts 21400899 A W 2 9.1 2 4.4 18.4 2 missed 2.6 brian roberts 21400899 A W 4 14.5 11 9.0 20.7 2 missed 6.1 brian roberts 21400899 A W 4 3.4 3 2.5 3.5 2 made 2.1 brian roberts 21400899 A W 4 12.4 0 0.8 24.6 3 missed 7.3 brian roberts 21400890 H W 2 17.4 0 1.1 22.4 3 missed 19.8 brian roberts 21400890 H W 2 16.0 8 7.5 24.5 3 missed 4.7 brian roberts 21400890 H W 4 12.1 14 11.9 14.6 2 made 1.8 brian roberts 21400890 H W 4 4.3 2 2.9 5.9 2 made 5.4 brian roberts 21400882 A W 4 4.4 0 0.8 26.4 3 missed 4.4 brian roberts 21400859 A L 1 6.8 0 0.5 22.8 3 missed 5.3 brian roberts 21400859 A L 2 6.4 3 2.7 24.7 3 made 5.6 brian roberts 21400859 A L 2 17.6 6 5.1 25.0 3 missed 5.4 brian roberts 21400859 A L 4 8.7 1 0.9 25.6 3 missed 5.1 brian roberts 21400859 A L 4 20.8 0 1.2 24.2 3 made 11.1 brian roberts 21400845 A W 1 17.5 2 2.2 25.4 3 missed 3.5 brian roberts "]
]
